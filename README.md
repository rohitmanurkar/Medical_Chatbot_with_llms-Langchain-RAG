üíä Medical Chatbot with RAG using Gemini, LangChain & Pinecone
This project is a sophisticated medical chatbot built to answer health-related questions. It leverages a Retrieval-Augmented Generation (RAG) architecture, ensuring that responses are not only generated by Google's powerful Gemini 2.5 Flash model but are also grounded in a reliable medical knowledge base.

The application is built with LangChain for orchestrating the different components, Pinecone as the vector database for efficient knowledge retrieval, and Flask as the web framework.

üèõÔ∏è Architecture & How It Works
The chatbot follows a RAG pipeline to provide accurate, context-aware answers:

Data Ingestion: Medical data is processed, and its embeddings are generated (e.g., using Google's embedding models).

Vector Storage: These embeddings are stored and indexed in a Pinecone vector database for fast similarity searches.

User Query: A user sends a question through the Flask web interface.

Retrieval: LangChain takes the user's query, converts it into an embedding, and searches Pinecone for the most relevant medical context.

Generation: The retrieved context and the original query are passed to Google's Gemini 2.5 Flash model. The LLM generates a human-like, accurate response based on the provided information.

Response: The final answer is sent back to the user via the Flask UI.

üõ†Ô∏è Tech Stack
Backend: Python, Flask

- LLM Orchestration: LangChain

- LLM: Google Gemini 2.5 Flash

- Vector Database: Pinecone

üöÄ Getting Started: Local Setup

Follow these steps to set up and run the project on your local machine.


1. Clone the Repository

2. Create and Activate Conda Environment

This will create a dedicated environment with Python 3.10.

```bash
conda create -n medibot python=3.10 -y
conda activate medibot
```

3. Install Dependencies

Install all the required Python packages from your `requirements.txt` file.

pip install -r requirements.txt


4. Set Up Environment Variables

Create a file named `.env` in the root directory of the project and add your API keys. **This is a crucial step.**

```ini
PINECONE_API_KEY="YOUR_PINECONE_API_KEY"
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"
```


5. Ingest Data into Pinecone

Run the following script to process your medical data and store its embeddings in your Pinecone index. This only needs to be done once.

```bash
python store_index.py
```


6. Run the Flask Application

Start the web server to interact with your chatbot.

```bash
python app.py
```

Now, open your web browser and navigate to `http://127.0.0.1:5000` to start chatting\!